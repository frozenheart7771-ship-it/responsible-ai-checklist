# AI Usage Checklist

This checklist is designed to provide a simple, practical way for organisations to review AI-assisted work before it is approved, shared, or acted upon.

It is intentionally non-technical and can be used by managers, team leads, educators, and reviewers.

The checklist should be applied whenever AI tools are used to support decisions, generate content, analyse information, or assist with operational tasks.

---

## Before using AI output, ask the following questions

### 1. Has a human reviewed the output carefully?
AI tools can make mistakes, hallucinate information, or miss context.

No AI-generated output should be used without a clear human review and judgement.

---

### 2. Was any sensitive or confidential data uploaded?
Consider whether the AI tool was given:
- personal data
- customer information
- financial details
- internal strategy
- health or educational records

If the answer is yes, stop and reassess whether AI should have been used at all.

---

### 3. Do we understand where the data goes?
If it is unclear how the AI tool stores, processes, or reuses information, it should be treated as untrusted.

Uncertainty itself is a risk.

---

### 4. Can the result be explained to others?
If the output cannot be explained in simple terms, it should not be relied upon for important decisions.

Explainability is a basic requirement for trust.

---

### 5. Is the output being used as advice or as a final decision?
AI should support thinking, not replace accountability.

Final decisions must always remain with a human owner.

---

### 6. Would we be comfortable if this output became public?
Ask whether the AI-assisted content would:
- damage trust
- cause embarrassment
- raise legal or ethical concerns
- harm individuals or organisations

If yes, it should not be used.

---

### 7. Who is responsible if something goes wrong?
There must always be a named human owner responsible for approving the final outcome.

Responsibility cannot be delegated to a tool.

---

## How to use this checklist in practice

- Apply it during reviews, not after problems occur
- Encourage teams to slow down when answers are unclear
- Treat the checklist as a safeguard, not an obstacle
- Update it as tools and risks evolve

Small pauses prevent large mistakes.

---

## Final note

This checklist is not about fear or control.

It exists to help organisations adopt AI thoughtfully, protect people and data, and build trust in AI-assisted work.
